{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "midterm_evaluation_template.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgKDr1L2SkwW"
      },
      "source": [
        "Name: \n",
        "\n",
        "ID: \n",
        "\n",
        "Link to your midterm project: https://colab.research.google.com/drive/LINK_TO_YOUR_PROJECT\n",
        "\n",
        "Link to your evaluation script: https://colab.research.google.com/drive/LINK_TO_YOUR_EVALUATION\n",
        "\n",
        "These links should be shared to the web without any permission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6jI4LX2TDS_"
      },
      "source": [
        "# Edit the paths if neccessary\n",
        "evaluation_data_path = \"/content/data/sample_evaluation_data.csv\"\n",
        "cls_weight_path = \"/content/weights/cls_model.pkl\"\n",
        "reg_weight_path = \"/content/weights/reg_model.pkl\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1EniWt79ikB"
      },
      "source": [
        "# Caution\n",
        "\n",
        "This code is only for model loading and evaluation.\n",
        "\n",
        "Don't include code for training your model here.\n",
        "\n",
        "We may terminate codes with very long execution time (i.e. 0 points) due to model training. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uu5PnMgz5oVi"
      },
      "source": [
        "# Load Best Model\n",
        "\n",
        "Write your own model load function.\n",
        "\n",
        "This function will be used in the below evaluation script.\n",
        "\n",
        "However, it should have the same structure as the below template (i.e. the name of the function, input arguments, output variables should be same).\n",
        "\n",
        "Scikit-learn Example: https://scikit-learn.org/stable/modules/model_persistence.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCLIgD_a455y"
      },
      "source": [
        "def load_best_classifier():\n",
        "    model = None\n",
        "    \n",
        "    # Write your load function for classifier model here\n",
        "    # model = \n",
        "\n",
        "    return model\n",
        "\n",
        "def load_best_regressor():\n",
        "    model = None\n",
        "\n",
        "    # Write your load function for regression model here\n",
        "    # model = \n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uftEXcwzUxO6"
      },
      "source": [
        "# Evaluation Function\n",
        "\n",
        "Write your own evaluation function.\n",
        "\n",
        "This function will be used in the below evaluation script.\n",
        "\n",
        "However, it should have the same structure as the below template (i.e. the name of the function, input arguments, output variables should be same).\n",
        "\n",
        "Note: Missing data is converted to `nan`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSl5k89KTm9b"
      },
      "source": [
        "def read_csv_and_classify(eval_data, cls_model):\n",
        "    scores = np.zeros(shape=len(eval_data), dtype=np.uint8)\n",
        "\n",
        "    # Write your evaluation script here\n",
        "    # scores = \n",
        "\n",
        "    return scores # Should be a numpy array with shape=(len(eval_data), 1) and data type=np.uint8\n",
        "\n",
        "def read_csv_and_regress(eval_data, reg_model):\n",
        "    scores = np.zeros(shape=(len(eval_data), 3), dtype=np.float32)\n",
        "\n",
        "    # Write your evaluation script here\n",
        "    # scores = \n",
        "\n",
        "    return scores # Should be a numpy array with shape=(len(eval_data), 3) and data type=np.float32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__Wj51czS1ad"
      },
      "source": [
        "# Evaluation Script: DO NOT EDIT FROM THIS POINT\n",
        "\n",
        "The below code should run as-is (otherwise your evaluation score may be considered as 0).\n",
        "\n",
        "Instructions\n",
        "\n",
        "1. Upload \"sample_evaluation_data.csv\" to `data_path`\n",
        "1. Write your evaluation functions\n",
        "1. Run the below code to get your evaluation scores\n",
        "\n",
        "Note: Missing data is converted to `nan`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-LO19reTXFj"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        " \n",
        "# Load Data\n",
        "with open(evaluation_data_path, \"r\") as f:\n",
        "    eval_lines = f.read().strip().split(\"\\n\")\n",
        "    eval_header = eval_lines[0]\n",
        "    eval_data = eval_lines[1:]\n",
        " \n",
        "eval_data = np.array([[ff  if ff!=\"\" else \"nan\" for ff in fff.strip().split(\",\")] for fff in eval_data], dtype=np.float32)\n",
        " \n",
        "# Load Weights\n",
        "best_classification_model = load_best_classifier()\n",
        "best_regression_model = load_best_regressor()\n",
        " \n",
        "# Calculate scores\n",
        "cls_scores = read_csv_and_classify(eval_data[:, 4:], best_classification_model)\n",
        "reg_scores = read_csv_and_regress(eval_data[:, 4:], best_regression_model)\n",
        " \n",
        "# Check scores\n",
        "assert cls_scores.shape==(len(eval_data),), \"Classification score shape mismatch\"\n",
        "assert reg_scores.shape==(len(eval_data),3), \"Regression score shape mismatch\"\n",
        "assert cls_scores.dtype==np.uint8, \"Classification score data type mismatch\"\n",
        "assert reg_scores.dtype==np.float32, \"Regression score data type mismatch\"\n",
        " \n",
        "# Save and download scores\n",
        "eval_data[:, 0] = cls_scores\n",
        "eval_data[:, 1:4] = reg_scores\n",
        " \n",
        "with open(evaluation_data_path, \"w\") as f:\n",
        "    f.write(eval_header+\"\\n\"+\"\\n\".join([\",\".join([str(ff) for ff in fff]) for fff in eval_data]))\n",
        " \n",
        "files.download(evaluation_data_path)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}